{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sathi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "Thanks to our talented, generous and civic-minded contributors from around \n",
      "the world who continue to stick with us and share their data and insight, and deep \n",
      "appreciation for our very own Verizon Threat Research Advisory Center (VTRAC) \n",
      "team (rock stars that they are). Welcome to Verizon’s 2024 Data Breach Investigations Report (DBIR). If you would like to provide people a copy of the \n",
      "report, we ask that you provide them a link to verizon.com/dbir rather than the PDF. 2024 DBIR Summary of findings\n",
      "Figure 1. From the exploitation of well-known \n",
      "and far-reaching zero-day vulnerabilities, such as the one that affected MOVEit, to \n",
      "the much more mundane but still incredibly effective Ransomware and Denial of \n",
      "Service (DoS) attacks, criminals continue to do their utmost to prove the old adage \n",
      "“crime does not pay” wrong. The shifting landscape of cyber threats can be confusing and overwhelming. The past year has been a busy one for cybercrime. In short, those are \n",
      "breaches an organization could \n",
      "potentially mitigate or prevent by trying \n",
      "to select vendors with better security \n",
      "track records. Similarly, over the past two years, we \n",
      "have seen incidents involving Pretexting \n",
      "(the majority of which had Business \n",
      "Email Compromise [BEC] as the \n",
      "outcome) accounting for one-fourth \n",
      "(ranging between 24% and 25%) of \n",
      "financially motivated attacks. As one might imagine, the main \n",
      "vector for those initial entry points was \n",
      "Web applications. Ransomware and Extortion breaches over time\n",
      "Summary of findings\n",
      "Our ways-in analysis witnessed a \n",
      "substantial growth of attacks involving \n",
      "the exploitation of vulnerabilities as the \n",
      "critical path to initiate a breach when \n",
      "compared to previous years. Last, but certainly not least, we extend a most sincere thanks yet again to our \n",
      "contributors (without whom we could not do this) and to our readers (without whom \n",
      "there would be no point in doing it). One might be forgiven for viewing the current state of cybersecurity \n",
      "as a colorful cyber Mardi Gras parade. Thus, the incidents \n",
      "described in this report took place between November 1, 2022, and October 31, \n",
      "2023. Exact quotes are permitted, \n",
      "but paraphrasing requires review. The overall reporting rate of Phishing \n",
      "has been growing over the past few \n",
      "years. These attacks were \n",
      "primarily leveraged by Ransomware \n",
      "and other Extortion-related threat \n",
      "actors. 8\n",
      "2024 DBIR Summary of findings\n",
      "We have revised our calculation of the \n",
      "involvement of the human element to \n",
      "exclude malicious Privilege Misuse in \n",
      "an effort to provide a clearer metric of \n",
      "what security awareness can affect. Please email us at  \n",
      "dbircontributor@verizon.com. This validates \n",
      "our suspicion that errors are more \n",
      "prevalent than media or traditional \n",
      "incident response-driven bias would \n",
      "lead us to believe. The jokes, sadly, do not write themselves. But we do encourage those \n",
      "who are new to the DBIR to give it a read-through before diving into the report. You are permitted to include statistics, figures and other information from the report, \n",
      "provided that (a) you cite the source as “Verizon 2024 Data Breach Investigations \n",
      "Report” and (b) the content is not modified in any way. While the general structure of the report remains the same, long-time readers may \n",
      "notice a few changes. Phishing email report rate by click status\n",
      "Figure 5. When, \n",
      "in addition to the attack types mentioned above, one throws in factors such as the \n",
      "human element and/or poorly protected passwords, things become even more \n",
      "confused. It \n",
      "should help you get your bearings. Our dataset saw a growth of breaches \n",
      "involving Errors, now at 28%, as we \n",
      "broadened our contributor base to \n",
      "include several new mandatory breach \n",
      "notification entities. It almost \n",
      "tripled (180% increase) from last year, \n",
      "which will come as no surprise to \n",
      "anyone who has been following the \n",
      "effect of MOVEit and similar zero-day \n",
      "vulnerabilities. If your organization aggregates incident or security data and is interested \n",
      "in becoming a contributor to the annual Verizon DBIR (and we hope you \n",
      "are), the process is very easy and straightforward.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "def bert_summarization(text, num_sentences=30):\n",
    "    # Load pre-trained BERT model and tokenizer\n",
    "    model_name = 'bert-base-uncased'\n",
    "    model = BertModel.from_pretrained(model_name)\n",
    "    tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    # Tokenize the text into sentences\n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    # Encode sentences\n",
    "    inputs = tokenizer(sentences, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "\n",
    "    # Generate embeddings for each sentence\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Get the CLS token embeddings for each sentence\n",
    "    sentence_embeddings = outputs.last_hidden_state[:, 0, :].numpy()\n",
    "\n",
    "    # Calculate similarity of each sentence to the mean sentence embedding\n",
    "    document_embedding = np.mean(sentence_embeddings, axis=0)\n",
    "    similarities = np.dot(sentence_embeddings, document_embedding)\n",
    "    \n",
    "    # Rank sentences by similarity\n",
    "    ranked_sentence_indices = np.argsort(similarities)[::-1]\n",
    "    \n",
    "    # Select top N sentences for the summary\n",
    "    selected_indices = ranked_sentence_indices[:num_sentences]\n",
    "    summary_sentences = [sentences[i] for i in selected_indices]\n",
    "    \n",
    "    # Join selected sentences into a summary\n",
    "    summary = ' '.join(summary_sentences)\n",
    "    return summary\n",
    "\n",
    "# Example usage\n",
    "\n",
    "import pymupdf # imports the pymupdf library\n",
    "text = \"\"\n",
    "doc = pymupdf.open(\"./app/first_chapter.pdf\") # open a document\n",
    "for page in doc: # iterate the document pages\n",
    "  text += page.get_text() # get plain text encoded as UTF-8\n",
    "\n",
    "summary = bert_summarization(text)\n",
    "print(\"Summary:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. check_pairwise_arrays expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Calculate similarity with document embedding (average of all sentence embeddings)\u001b[39;00m\n\u001b[0;32m     26\u001b[0m doc_embedding \u001b[38;5;241m=\u001b[39m sentence_embeddings\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 27\u001b[0m similarities \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdoc_embedding\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentence_embeddings\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Rank sentences by similarity score\u001b[39;00m\n\u001b[0;32m     30\u001b[0m sentence_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(sentences, similarities))\n",
      "File \u001b[1;32mc:\\Users\\sathi\\OneDrive\\Desktop\\main\\.venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\sathi\\OneDrive\\Desktop\\main\\.venv\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1668\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1624\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute cosine similarity between samples in X and Y.\u001b[39;00m\n\u001b[0;32m   1625\u001b[0m \n\u001b[0;32m   1626\u001b[0m \u001b[38;5;124;03mCosine similarity, or the cosine kernel, computes similarity as the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1664\u001b[0m \u001b[38;5;124;03m       [0.57..., 0.81...]])\u001b[39;00m\n\u001b[0;32m   1665\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1666\u001b[0m \u001b[38;5;66;03m# to avoid recursive import\u001b[39;00m\n\u001b[1;32m-> 1668\u001b[0m X, Y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_pairwise_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1670\u001b[0m X_normalized \u001b[38;5;241m=\u001b[39m normalize(X, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m Y:\n",
      "File \u001b[1;32mc:\\Users\\sathi\\OneDrive\\Desktop\\main\\.venv\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:174\u001b[0m, in \u001b[0;36mcheck_pairwise_arrays\u001b[1;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, ensure_2d, copy)\u001b[0m\n\u001b[0;32m    164\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m    165\u001b[0m         X,\n\u001b[0;32m    166\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    171\u001b[0m         ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m    172\u001b[0m     )\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 174\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    183\u001b[0m     Y \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m    184\u001b[0m         Y,\n\u001b[0;32m    185\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    190\u001b[0m         ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m    191\u001b[0m     )\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m precomputed:\n",
      "File \u001b[1;32mc:\\Users\\sathi\\OneDrive\\Desktop\\main\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1053\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1048\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1049\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1050\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1051\u001b[0m     )\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nd \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m-> 1053\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1054\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1055\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m   1056\u001b[0m     )\n\u001b[0;32m   1058\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m   1059\u001b[0m     _assert_all_finite(\n\u001b[0;32m   1060\u001b[0m         array,\n\u001b[0;32m   1061\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m   1062\u001b[0m         estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[0;32m   1063\u001b[0m         allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1064\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with dim 3. check_pairwise_arrays expected <= 2."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Load BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Sample text and keywords\n",
    "text = \"Your text to be summarized goes here. It should be relatively long to demonstrate the summarization.\"\n",
    "keywords = [\"keyword1\", \"keyword2\"]\n",
    "\n",
    "# Split text into sentences\n",
    "sentences = text.split('. ')\n",
    "\n",
    "# Encode sentences\n",
    "def encode_sentence(sentence):\n",
    "    inputs = tokenizer(sentence, return_tensors='pt')\n",
    "    outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
    "\n",
    "sentence_embeddings = np.array([encode_sentence(sentence) for sentence in sentences])\n",
    "\n",
    "# Calculate similarity with document embedding (average of all sentence embeddings)\n",
    "doc_embedding = sentence_embeddings.mean(axis=0)\n",
    "similarities = cosine_similarity([doc_embedding], sentence_embeddings).flatten()\n",
    "\n",
    "# Rank sentences by similarity score\n",
    "sentence_scores = list(zip(sentences, similarities))\n",
    "sentence_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Ensure sentences with keywords are included\n",
    "keyword_sentences = [sentence for sentence in sentences if any(keyword in sentence for keyword in keywords)]\n",
    "\n",
    "# Combine top-ranked sentences and keyword sentences\n",
    "selected_sentences = {sentence for sentence, _ in sentence_scores[:5]} | set(keyword_sentences)\n",
    "\n",
    "# Maintain original order for the summary\n",
    "ordered_summary = [sentence for sentence in sentences if sentence in selected_sentences]\n",
    "\n",
    "summary = '. '.join(ordered_summary)\n",
    "\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select action varieties in Financial motive over time\n",
      ". Phishing email report rate by click status\n",
      "Figure 5. In short, those are \n",
      "breaches an organization could \n",
      "potentially mitigate or prevent by trying \n",
      "to select vendors with better security \n",
      "track records. Pure Extortion \n",
      "attacks have risen over the past year \n",
      "and are now a component of 9% of \n",
      "all breaches. As one might imagine, the main \n",
      "vector for those initial entry points was \n",
      "Web applications.\n",
      "2024 DBIR Summary of findings\n",
      "Figure 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to tokenize and encode sentences\n",
    "def encode_sentences(sentences):\n",
    "    encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "    return model_output.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Function to perform extractive summarization\n",
    "def extractive_summarization(text, keywords, top_n=5):\n",
    "    # Split the document into sentences\n",
    "    sentences = text.split('. ')\n",
    "    # Encode sentences\n",
    "    sentence_embeddings = encode_sentences(sentences)\n",
    "    \n",
    "    # Encode keywords\n",
    "    keyword_embeddings = encode_sentences(keywords)\n",
    "    \n",
    "    # Calculate cosine similarity between sentences and keywords\n",
    "    similarities = []\n",
    "    for sentence_embedding in sentence_embeddings:\n",
    "        similarity = max(cosine_similarity([sentence_embedding], keyword_embeddings).flatten())\n",
    "        similarities.append(similarity)\n",
    "    \n",
    "    # Rank sentences based on similarity scores\n",
    "    ranked_sentences = [sentence for _, sentence in sorted(zip(similarities, sentences), reverse=True)]\n",
    "    \n",
    "    # Select top n sentences\n",
    "    summary = '. '.join(ranked_sentences[:top_n])\n",
    "    return summary\n",
    "\n",
    "# Example usage\n",
    "import pymupdf # imports the pymupdf library\n",
    "text = \"\"\n",
    "doc = pymupdf.open(\"./app/first_chapter.pdf\") # open a document\n",
    "for page in doc: # iterate the document pages\n",
    "  text += page.get_text() # get plain text encoded as UTF-8\n",
    "keywords = [\"security\", \"threat\", \"crime\"]\n",
    "summary = extractive_summarization(text, keywords)\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
