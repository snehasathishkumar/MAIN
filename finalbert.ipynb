{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: 5\n",
      "2024 DBIR Introduction\n",
      "Introduction\n",
      "Greetings! Welcome to Verizon’s 2024 Data Breach Investigations Report (DBIR). Thanks to our talented, generous and civic-minded contributors from around \n",
      "the world who continue to stick with us and share their data and insight, and deep \n",
      "appreciation for our very own Verizon Threat Research Advisory Center (VTRAC) \n",
      "team (rock stars that they are). These two groups enable us to examine and analyze \n",
      "relevant trends in cybercrime that play out on a global stage across organizations of \n",
      "all sizes and types.\n",
      "From year to year, we see new and innovative attacks as well as variations on tried-\n",
      "and-true attacks that still remain successful. From the exploitation of well-known \n",
      "and far-reaching zero-day vulnerabilities, such as the one that affected MOVEit, to \n",
      "the much more mundane but still incredibly effective Ransomware and Denial of \n",
      "Service (DoS) attacks, criminals continue to do their utmost to prove the old adage \n",
      "“crime does not pay” wrong.\n",
      "The shifting landscape of cyber threats can be confusing and overwhelming. One might be forgiven for viewing the current state of cybersecurity \n",
      "as a colorful cyber Mardi Gras parade. Enterprise floats of all shapes and sizes \n",
      "cruising past a large crowd of threat actors who are shouting out gleefully “Throw \n",
      "me some creds!” Of course, human nature being what it is, all too often, the folks \n",
      "on the floats do just that. We \n",
      "analyzed 30,458 real-world security incidents, of which 10,626 were confirmed data \n",
      "breaches (a record high!), with victims spanning 94 countries.\n",
      "While the general structure of the report remains the same, long-time readers may \n",
      "notice a few changes. But we do encourage those \n",
      "who are new to the DBIR to give it a read-through before diving into the report. David Hylender, Philippe Langlois, Alex Pinto, Suzanne Widup\n",
      "Very special thanks to:\n",
      "– Christopher Novak for his continued support and insight\n",
      "– Dave Kennedy and Erika Gifford from VTRAC\n",
      "– \u0007\n",
      "Kate Kutchko, Marziyeh Khanouki and Yoni Fridman from the Verizon Business \n",
      "Product Data Science Team\n",
      "6\n",
      "2024 DBIR Helpful guidance\n",
      "Helpful guidance\n",
      "About the 2024 DBIR incident dataset\n",
      "Each year, the DBIR timeline for in-scope incidents is from November 1 of one \n",
      "calendar year through October 31 of the next calendar year. The 2023 caseload is the primary analytical focus of the 2024 report, but \n",
      "the entire range of data is referenced throughout, notably in trending graphs. The \n",
      "time between the latter date and the date of publication for this report is spent in \n",
      "acquiring the data from our global contributors, anonymizing and aggregating that \n",
      "data, analyzing the dataset, and finally creating the graphics and writing the report. \n",
      "The jokes, sadly, do not write themselves.\n",
      "Credit where credit is due\n",
      "Turns out folks enjoy citing the report, and we often get asked how to go about \n",
      "doing it.\n",
      "You are permitted to include statistics, figures and other information from the report, \n",
      "provided that (a) you cite the source as “Verizon 2024 Data Breach Investigations \n",
      "Report” and (b) the content is not modified in any way. Got a data question?  \n",
      "Tweet @VZDBIR!\n",
      "If your organization aggregates incident or security data and is interested \n",
      "in becoming a contributor to the annual Verizon DBIR (and we hope you \n",
      "are), the process is very easy and straightforward. Ransomware and Extortion breaches over time\n",
      "Summary of findings\n",
      "Our ways-in analysis witnessed a \n",
      "substantial growth of attacks involving \n",
      "the exploitation of vulnerabilities as the \n",
      "critical path to initiate a breach when \n",
      "compared to previous years. It almost \n",
      "tripled (180% increase) from last year, \n",
      "which will come as no surprise to \n",
      "anyone who has been following the \n",
      "effect of MOVEit and similar zero-day \n",
      "vulnerabilities. These attacks were \n",
      "primarily leveraged by Ransomware \n",
      "and other Extortion-related threat \n",
      "actors. As one might imagine, the main \n",
      "vector for those initial entry points was \n",
      "Web applications.\n",
      "2024 DBIR Summary of findings\n",
      "Figure 1. Select ways-in enumerations in non-Error, non-Misuse breaches \n",
      "(n=6,963)\n",
      "Roughly one-third of all breaches \n",
      "involved Ransomware or some other \n",
      "Extortion technique. Pure Extortion \n",
      "attacks have risen over the past year \n",
      "and are now a component of 9% of \n",
      "all breaches. The shift of traditional \n",
      "ransomware actors toward these newer \n",
      "techniques resulted in a bit of a decline \n",
      "in Ransomware to 23%. However, when \n",
      "combined, given that they share threat \n",
      "actors, they represent a strong growth \n",
      "to 32% of breaches. Ransomware was \n",
      "a top threat across 92% of industries.\n",
      "8\n",
      "2024 DBIR Summary of findings\n",
      "We have revised our calculation of the \n",
      "involvement of the human element to \n",
      "exclude malicious Privilege Misuse in \n",
      "an effort to provide a clearer metric of \n",
      "what security awareness can affect. For \n",
      "this year’s dataset, the human element \n",
      "was a component of 68% of breaches, \n",
      "roughly the same as the previous period \n",
      "described in the 2023 DBIR.\n",
      "In this issue, we are introducing an \n",
      "expanded concept of a breach involving \n",
      "a third party that includes partner \n",
      "infrastructure being affected and \n",
      "direct or indirect software supply chain \n",
      "issues—including when an organization \n",
      "is affected by vulnerabilities in third-\n",
      "party software. In short, those are \n",
      "breaches an organization could \n",
      "potentially mitigate or prevent by trying \n",
      "to select vendors with better security \n",
      "track records. We see this figure at \n",
      "15% this year, a 68% increase from the \n",
      "previous year, mostly fueled by the use \n",
      "of zero-day exploits for Ransomware \n",
      "and Extortion attacks.\n",
      "Our dataset saw a growth of breaches \n",
      "involving Errors, now at 28%, as we \n",
      "broadened our contributor base to \n",
      "include several new mandatory breach \n",
      "notification entities. This validates \n",
      "our suspicion that errors are more \n",
      "prevalent than media or traditional \n",
      "incident response-driven bias would \n",
      "lead us to believe.\n",
      "Figure 3. Phishing email report rate by click status\n",
      "2024 DBIR Summary of findings\n",
      "Financially motivated threat actors will \n",
      "typically stick to the attack techniques \n",
      "that will give them the most return  \n",
      "on investment.\n",
      "Over the past three years, the \n",
      "combination of Ransomware and \n",
      "other Extortion breaches accounted \n",
      "for almost two-thirds (fluctuating \n",
      "between 59% and 66%) of those \n",
      "attacks. According to the FBI’s \n",
      "Internet Crime Complaint Center \n",
      "(IC3) ransomware complaint data, \n",
      "the median loss associated with the \n",
      "combination of Ransomware and \n",
      "other Extortion breaches has been \n",
      "$46,000, ranging between $3 (three \n",
      "dollars) and $1,141,467 for 95% of the \n",
      "cases. We also found from ransomware \n",
      "negotiation data contributors that \n",
      "the median ratio of initially requested \n",
      "ransom and company revenue is 1.34%, \n",
      "but it fluctuated between 0.13% and \n",
      "8.30% for 80% of the cases.\n",
      "Similarly, over the past two years, we \n",
      "have seen incidents involving Pretexting \n",
      "(the majority of which had Business \n",
      "Email Compromise [BEC] as the \n",
      "outcome) accounting for one-fourth \n",
      "(ranging between 24% and 25%) of \n",
      "financially motivated attacks. In both \n",
      "years, the median transaction amount \n",
      "of a BEC was around $50,000, also \n",
      "according to the FBI IC3 dataset.\n",
      "The overall reporting rate of Phishing \n",
      "has been growing over the past few \n",
      "years. In security awareness exercise \n",
      "data contributed by our partners during \n",
      "2023, 20% of users reported phishing \n",
      "in simulation engagements, and 11% \n",
      "of the users who clicked the email \n",
      "also reported. This is welcome news \n",
      "because on the flip side, the median \n",
      "time to click on a malicious link after the \n",
      "email is opened is 21 seconds and then \n",
      "only another 28 seconds for the person \n",
      "caught in the phishing scheme to enter \n",
      "their data. This leads to an alarming \n",
      "finding: The median time for users  \n",
      "to fall for phishing emails is less than  \n",
      "60 seconds.\n",
      "Figure 4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Load pre-trained model tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    sentences = text.split('. ')\n",
    "    return sentences\n",
    "\n",
    "def get_sentence_embeddings(sentences, tokenizer, model):\n",
    "    embeddings = []\n",
    "    for sentence in sentences:\n",
    "        inputs = tokenizer(sentence, return_tensors='pt', truncation=True, padding=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        embeddings.append(outputs.last_hidden_state.mean(dim=1).squeeze().numpy())\n",
    "    return embeddings\n",
    "\n",
    "def rank_sentences(sentences, embeddings):\n",
    "    sentence_scores = []\n",
    "    for i, emb in enumerate(embeddings):\n",
    "        score = cosine_similarity([emb], embeddings).mean()\n",
    "        sentence_scores.append((score, i))\n",
    "    ranked_sentences = sorted(sentence_scores, reverse=True, key=lambda x: x[0])\n",
    "    return [sentences[i] for _, i in ranked_sentences]\n",
    "\n",
    "def keyword_relevant_sentences(sentences, keywords):\n",
    "    relevant_sentences = []\n",
    "    for sentence in sentences:\n",
    "        if any(keyword.lower() in sentence.lower() for keyword in keywords):\n",
    "            relevant_sentences.append(sentence)\n",
    "    return relevant_sentences\n",
    "\n",
    "def summarize(text, keywords, num_sentences=30):\n",
    "    sentences = preprocess_text(text)\n",
    "    embeddings = get_sentence_embeddings(sentences, tokenizer, model)\n",
    "    ranked_sentences = rank_sentences(sentences, embeddings)\n",
    "    \n",
    "    summary = ranked_sentences[:num_sentences]\n",
    "    relevant_sentences = keyword_relevant_sentences(sentences, keywords)\n",
    "    \n",
    "    # Ensure unique sentences in the final summary\n",
    "    final_summary_sentences = list(dict.fromkeys(summary + relevant_sentences))\n",
    "    \n",
    "    # Maintain the original order\n",
    "    final_summary_sentences_sorted = sorted(final_summary_sentences, key=lambda x: sentences.index(x))\n",
    "    \n",
    "    return '. '.join(final_summary_sentences_sorted)\n",
    "\n",
    "# Example usage\n",
    "# text = \"\"\"Your input text goes here. It should be a long paragraph with multiple sentences.\"\"\"\n",
    "# keywords = [\"keyword1\", \"keyword2\"]\n",
    "\n",
    "# summary = summarize(text, keywords)\n",
    "# print(\"Summary:\", summary)\n",
    "\n",
    "# text = \"\"\"Climate change is one of the most pressing issues of our time. Rising global temperatures have led to a variety of environmental impacts, including more frequent and severe weather events. The polar ice caps are melting at an alarming rate, causing sea levels to rise and threatening coastal communities. Additionally, changing weather patterns are affecting agriculture, making it more difficult for farmers to grow crops. Governments and organizations around the world are working to address climate change through various measures. Renewable energy sources, such as solar and wind power, are being developed to reduce reliance on fossil fuels. International agreements, like the Paris Agreement, aim to unite countries in the fight against climate change. Public awareness and education on the issue are also crucial for driving change. It is essential that everyone takes part in efforts to mitigate the effects of climate change to ensure a sustainable future for generations to come.\"\"\"\n",
    "import pymupdf\n",
    "\n",
    "extracted_text = \"\"\n",
    "doc = pymupdf.open(\"first_chapter.pdf\") # open a document\n",
    "for page in doc: # iterate the document pages\n",
    "    extracted_text += page.get_text() # get plain text encoded as UTF-8\n",
    "\n",
    "keywords = [\"threat\", \"ransomware\"]\n",
    "\n",
    "summary = summarize(extracted_text, keywords)\n",
    "print(\"Summary:\", summary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thanks to our talented, generous and civic-minded contributors from around \\nthe world who continue to stick with us and share their data and insight, and deep \\nappreciation for our very own Verizon Threat Research Advisory Center (VTRAC) \\nteam (rock stars that they are)',\n",
       " ' From the exploitation of well-known \\nand far-reaching zero-day vulnerabilities, such as the one that affected MOVEit, to \\nthe much more mundane but still incredibly effective Ransomware and Denial of \\nService (DoS) attacks, criminals continue to do their utmost to prove the old adage \\n“crime does not pay” wrong',\n",
       " '\\nThe shifting landscape of cyber threats can be confusing and overwhelming',\n",
       " ' Enterprise floats of all shapes and sizes \\ncruising past a large crowd of threat actors who are shouting out gleefully “Throw \\nme some creds!” Of course, human nature being what it is, all too often, the folks \\non the floats do just that',\n",
       " ' We \\nanalyzed 30,458 real-world security incidents, of which 10,626 were confirmed data \\nbreaches (a record high!), with victims spanning 94 countries',\n",
       " '\\nWhile the general structure of the report remains the same, long-time readers may \\nnotice a few changes',\n",
       " ' Ransomware and Extortion breaches over time\\nSummary of findings\\nOur ways-in analysis witnessed a \\nsubstantial growth of attacks involving \\nthe exploitation of vulnerabilities as the \\ncritical path to initiate a breach when \\ncompared to previous years',\n",
       " ' These attacks were \\nprimarily leveraged by Ransomware \\nand other Extortion-related threat \\nactors',\n",
       " ' Select ways-in enumerations in non-Error, non-Misuse breaches \\n(n=6,963)\\nRoughly one-third of all breaches \\ninvolved Ransomware or some other \\nExtortion technique',\n",
       " ' The shift of traditional \\nransomware actors toward these newer \\ntechniques resulted in a bit of a decline \\nin Ransomware to 23%',\n",
       " ' However, when \\ncombined, given that they share threat \\nactors, they represent a strong growth \\nto 32% of breaches',\n",
       " ' Ransomware was \\na top threat across 92% of industries',\n",
       " '\\n8\\n2024 DBIR Summary of findings\\nWe have revised our calculation of the \\ninvolvement of the human element to \\nexclude malicious Privilege Misuse in \\nan effort to provide a clearer metric of \\nwhat security awareness can affect',\n",
       " ' For \\nthis year’s dataset, the human element \\nwas a component of 68% of breaches, \\nroughly the same as the previous period \\ndescribed in the 2023 DBIR',\n",
       " '\\nIn this issue, we are introducing an \\nexpanded concept of a breach involving \\na third party that includes partner \\ninfrastructure being affected and \\ndirect or indirect software supply chain \\nissues—including when an organization \\nis affected by vulnerabilities in third-\\nparty software',\n",
       " ' We see this figure at \\n15% this year, a 68% increase from the \\nprevious year, mostly fueled by the use \\nof zero-day exploits for Ransomware \\nand Extortion attacks',\n",
       " '\\nOur dataset saw a growth of breaches \\ninvolving Errors, now at 28%, as we \\nbroadened our contributor base to \\ninclude several new mandatory breach \\nnotification entities',\n",
       " ' Phishing email report rate by click status\\n2024 DBIR Summary of findings\\nFinancially motivated threat actors will \\ntypically stick to the attack techniques \\nthat will give them the most return  \\non investment',\n",
       " '\\nOver the past three years, the \\ncombination of Ransomware and \\nother Extortion breaches accounted \\nfor almost two-thirds (fluctuating \\nbetween 59% and 66%) of those \\nattacks',\n",
       " ' According to the FBI’s \\nInternet Crime Complaint Center \\n(IC3) ransomware complaint data, \\nthe median loss associated with the \\ncombination of Ransomware and \\nother Extortion breaches has been \\n$46,000, ranging between $3 (three \\ndollars) and $1,141,467 for 95% of the \\ncases',\n",
       " ' We also found from ransomware \\nnegotiation data contributors that \\nthe median ratio of initially requested \\nransom and company revenue is 1',\n",
       " '34%, \\nbut it fluctuated between 0',\n",
       " '13% and \\n8',\n",
       " '30% for 80% of the cases',\n",
       " '\\nSimilarly, over the past two years, we \\nhave seen incidents involving Pretexting \\n(the majority of which had Business \\nEmail Compromise [BEC] as the \\noutcome) accounting for one-fourth \\n(ranging between 24% and 25%) of \\nfinancially motivated attacks']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary.split(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like dogs cats.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sathi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "def split_into_phrases(sentence):\n",
    "    # Tokenize the sentence into words\n",
    "    words = word_tokenize(sentence)\n",
    "    \n",
    "    # Detect the subject and verb\n",
    "    subject_verb = []\n",
    "    for word in words:\n",
    "        if word.lower() not in ['and', 'or', ',']:\n",
    "            subject_verb.append(word)\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    # Identify the subject and verb phrase\n",
    "    subject_verb_phrase = TreebankWordDetokenizer().detokenize(subject_verb)\n",
    "    \n",
    "    # Create a list to store phrases\n",
    "    phrases = []\n",
    "    \n",
    "    # Temporary list to store current phrase\n",
    "    current_phrase = []\n",
    "    \n",
    "    # Iterate through words starting after the subject and verb\n",
    "    for word in words[len(subject_verb):]:\n",
    "        if word.lower() in ['and', 'or', ',']:\n",
    "            if current_phrase:\n",
    "                phrase = subject_verb_phrase + ' ' + TreebankWordDetokenizer().detokenize(current_phrase)\n",
    "                phrases.append(phrase)\n",
    "                current_phrase = []\n",
    "        else:\n",
    "            current_phrase.append(word)\n",
    "    \n",
    "    # Add the last phrase if it exists\n",
    "    if current_phrase:\n",
    "        phrase = subject_verb_phrase + ' ' + TreebankWordDetokenizer().detokenize(current_phrase)\n",
    "        phrases.append(phrase)\n",
    "    \n",
    "    return phrases\n",
    "\n",
    "# Test the function\n",
    "sentence = \"I like dogs and cats.\"\n",
    "phrases = split_into_phrases(sentence)\n",
    "for phrase in phrases:\n",
    "    print(phrase)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
