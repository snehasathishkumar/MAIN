{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: Rising global temperatures have led to a variety of environmental impacts, including more frequent and severe weather events. Governments and organizations around the world are working to address climate change through various measures. Renewable energy sources, such as solar and wind power, are being developed to reduce reliance on fossil fuels. International agreements, like the Paris Agreement, aim to unite countries in the fight against climate change. It is essential that everyone takes part in efforts to mitigate the effects of climate change to ensure a sustainable future for generations to come.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Load pre-trained model tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    sentences = text.split('. ')\n",
    "    return sentences\n",
    "\n",
    "def get_sentence_embeddings(sentences, tokenizer, model):\n",
    "    embeddings = []\n",
    "    for sentence in sentences:\n",
    "        inputs = tokenizer(sentence, return_tensors='pt', truncation=True, padding=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        embeddings.append(outputs.last_hidden_state.mean(dim=1).squeeze().numpy())\n",
    "    return embeddings\n",
    "\n",
    "def rank_sentences(sentences, embeddings):\n",
    "    sentence_scores = []\n",
    "    for i, emb in enumerate(embeddings):\n",
    "        score = cosine_similarity([emb], embeddings).mean()\n",
    "        sentence_scores.append((score, i))\n",
    "    ranked_sentences = sorted(sentence_scores, reverse=True, key=lambda x: x[0])\n",
    "    return [sentences[i] for _, i in ranked_sentences]\n",
    "\n",
    "def keyword_relevant_sentences(sentences, keywords):\n",
    "    relevant_sentences = []\n",
    "    for sentence in sentences:\n",
    "        if any(keyword.lower() in sentence.lower() for keyword in keywords):\n",
    "            relevant_sentences.append(sentence)\n",
    "    return relevant_sentences\n",
    "\n",
    "def summarize(text, keywords, num_sentences=5):\n",
    "    sentences = preprocess_text(text)\n",
    "    embeddings = get_sentence_embeddings(sentences, tokenizer, model)\n",
    "    ranked_sentences = rank_sentences(sentences, embeddings)\n",
    "    \n",
    "    summary = ranked_sentences[:num_sentences]\n",
    "    relevant_sentences = keyword_relevant_sentences(sentences, keywords)\n",
    "    \n",
    "    # Ensure unique sentences in the final summary\n",
    "    final_summary_sentences = list(dict.fromkeys(summary + relevant_sentences))\n",
    "    \n",
    "    # Maintain the original order\n",
    "    final_summary_sentences_sorted = sorted(final_summary_sentences, key=lambda x: sentences.index(x))\n",
    "    \n",
    "    return '. '.join(final_summary_sentences_sorted)\n",
    "\n",
    "# Example usage\n",
    "# text = \"\"\"Your input text goes here. It should be a long paragraph with multiple sentences.\"\"\"\n",
    "# keywords = [\"keyword1\", \"keyword2\"]\n",
    "\n",
    "# summary = summarize(text, keywords)\n",
    "# print(\"Summary:\", summary)\n",
    "\n",
    "text = \"\"\"Climate change is one of the most pressing issues of our time. Rising global temperatures have led to a variety of environmental impacts, including more frequent and severe weather events. The polar ice caps are melting at an alarming rate, causing sea levels to rise and threatening coastal communities. Additionally, changing weather patterns are affecting agriculture, making it more difficult for farmers to grow crops. Governments and organizations around the world are working to address climate change through various measures. Renewable energy sources, such as solar and wind power, are being developed to reduce reliance on fossil fuels. International agreements, like the Paris Agreement, aim to unite countries in the fight against climate change. Public awareness and education on the issue are also crucial for driving change. It is essential that everyone takes part in efforts to mitigate the effects of climate change to ensure a sustainable future for generations to come.\"\"\"\n",
    "\n",
    "keywords = [\"Sneha\"]\n",
    "\n",
    "summary = summarize(text, keywords)\n",
    "print(\"Summary:\", summary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rising global temperatures have led to a variety of environmental impacts, including more frequent and severe weather events',\n",
       " ' Governments and organizations around the world are working to address climate change through various measures',\n",
       " ' Renewable energy sources, such as solar and wind power, are being developed to reduce reliance on fossil fuels',\n",
       " ' International agreements, like the Paris Agreement, aim to unite countries in the fight against climate change',\n",
       " ' It is essential that everyone takes part in efforts to mitigate the effects of climate change to ensure a sustainable future for generations to come',\n",
       " '']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary.split(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like dogs cats.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sathi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "def split_into_phrases(sentence):\n",
    "    # Tokenize the sentence into words\n",
    "    words = word_tokenize(sentence)\n",
    "    \n",
    "    # Detect the subject and verb\n",
    "    subject_verb = []\n",
    "    for word in words:\n",
    "        if word.lower() not in ['and', 'or', ',']:\n",
    "            subject_verb.append(word)\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    # Identify the subject and verb phrase\n",
    "    subject_verb_phrase = TreebankWordDetokenizer().detokenize(subject_verb)\n",
    "    \n",
    "    # Create a list to store phrases\n",
    "    phrases = []\n",
    "    \n",
    "    # Temporary list to store current phrase\n",
    "    current_phrase = []\n",
    "    \n",
    "    # Iterate through words starting after the subject and verb\n",
    "    for word in words[len(subject_verb):]:\n",
    "        if word.lower() in ['and', 'or', ',']:\n",
    "            if current_phrase:\n",
    "                phrase = subject_verb_phrase + ' ' + TreebankWordDetokenizer().detokenize(current_phrase)\n",
    "                phrases.append(phrase)\n",
    "                current_phrase = []\n",
    "        else:\n",
    "            current_phrase.append(word)\n",
    "    \n",
    "    # Add the last phrase if it exists\n",
    "    if current_phrase:\n",
    "        phrase = subject_verb_phrase + ' ' + TreebankWordDetokenizer().detokenize(current_phrase)\n",
    "        phrases.append(phrase)\n",
    "    \n",
    "    return phrases\n",
    "\n",
    "# Test the function\n",
    "sentence = \"I like dogs and cats.\"\n",
    "phrases = split_into_phrases(sentence)\n",
    "for phrase in phrases:\n",
    "    print(phrase)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
