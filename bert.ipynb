{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sathi\\OneDrive\\Desktop\\main\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       number incident_state  active  reassignment_count  reopen_count  \\\n",
      "0  INC0000045            New    True                   0             0   \n",
      "1  INC0000045       Resolved    True                   0             0   \n",
      "2  INC0000045       Resolved    True                   0             0   \n",
      "3  INC0000045         Closed   False                   0             0   \n",
      "4  INC0000047            New    True                   0             0   \n",
      "\n",
      "   sys_mod_count  made_sla    caller_id       opened_by        opened_at  ...  \\\n",
      "0              0      True  Caller 2403    Opened by  8  29/2/2016 01:16  ...   \n",
      "1              2      True  Caller 2403    Opened by  8  29/2/2016 01:16  ...   \n",
      "2              3      True  Caller 2403    Opened by  8  29/2/2016 01:16  ...   \n",
      "3              4      True  Caller 2403    Opened by  8  29/2/2016 01:16  ...   \n",
      "4              0      True  Caller 2403  Opened by  397  29/2/2016 04:40  ...   \n",
      "\n",
      "  u_priority_confirmation         notify problem_id rfc vendor caused_by  \\\n",
      "0                   False  Do Not Notify          ?   ?      ?         ?   \n",
      "1                   False  Do Not Notify          ?   ?      ?         ?   \n",
      "2                   False  Do Not Notify          ?   ?      ?         ?   \n",
      "3                   False  Do Not Notify          ?   ?      ?         ?   \n",
      "4                   False  Do Not Notify          ?   ?      ?         ?   \n",
      "\n",
      "  closed_code      resolved_by      resolved_at       closed_at  \n",
      "0      code 5  Resolved by 149  29/2/2016 11:29  5/3/2016 12:00  \n",
      "1      code 5  Resolved by 149  29/2/2016 11:29  5/3/2016 12:00  \n",
      "2      code 5  Resolved by 149  29/2/2016 11:29  5/3/2016 12:00  \n",
      "3      code 5  Resolved by 149  29/2/2016 11:29  5/3/2016 12:00  \n",
      "4      code 5   Resolved by 81   1/3/2016 09:52  6/3/2016 10:00  \n",
      "\n",
      "[5 rows x 36 columns]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'tolist'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31576\\925622426.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0membeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlast_hidden_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0membeddings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m# Extract text from the relevant column (example: 'Description')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mtexts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m# Compute BERT embeddings for each row's text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0membeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_bert_embeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sathi\\OneDrive\\Desktop\\main\\.venv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6295\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6296\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6297\u001b[0m         ):\n\u001b[0;32m   6298\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6299\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'tolist'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('incident_event_log.csv')\n",
    "\n",
    "# Display the first few rows to understand the structure\n",
    "print(df.head())\n",
    "\n",
    "# Define a function to compute BERT embeddings for sentences\n",
    "def get_bert_embeddings(text_list):\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    model = BertModel.from_pretrained('bert-base-uncased')\n",
    "    \n",
    "    inputs = tokenizer(text_list, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Use the [CLS] token embeddings as the sentence embedding\n",
    "    embeddings = outputs.last_hidden_state[:, 0, :].numpy()\n",
    "    return embeddings\n",
    "\n",
    "# Extract text from the relevant column (example: 'Description')\n",
    "texts = df.tolist()\n",
    "\n",
    "# Compute BERT embeddings for each row's text\n",
    "embeddings = get_bert_embeddings(texts)\n",
    "\n",
    "# Define a query to rank rows (example: 'important sales data')\n",
    "query = \"important sales data\"\n",
    "query_embedding = get_bert_embeddings([query])[0]\n",
    "\n",
    "# Compute cosine similarity between the query embedding and row embeddings\n",
    "similarities = cosine_similarity([query_embedding], embeddings).flatten()\n",
    "\n",
    "# Add similarities to the DataFrame and sort by similarity\n",
    "df['similarity'] = similarities\n",
    "summary_df = df.sort_values(by='similarity', ascending=False).head(5)\n",
    "\n",
    "# Display the summarized data\n",
    "print(\"Summary of Most Relevant Records:\")\n",
    "print(summary_df)\n",
    "\n",
    "# Save the summary to a new CSV file\n",
    "summary_df.to_csv('summary_most_relevant_records.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
